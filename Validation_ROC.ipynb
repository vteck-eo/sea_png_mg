# ==========================================================
# ðŸŒ Mangrove Probability Validation using ROC Analysis
# ==========================================================

# ==========================================================
# ðŸŒ 1. Initialize Google Earth Engine
# ==========================================================
import ee

try:
    ee.Initialize(project='')
except:
    ee.Authenticate()
    ee.Initialize(project='')

# Mount Google Drive (for CSV input/output)
from google.colab import drive
drive.mount('/content/drive')

DATA_DIR = "/content/drive/MyDrive/username folder"

import os
print("Available files:", os.listdir(DATA_DIR))


# ==========================================================
# ðŸ“¥ 2. Load Validation Dataset (Reference Points)
# ==========================================================
# The CSV contains:
# - lon, lat
# - ref_2017 ... ref_2024 (binary reference labels)
# - additional attributes if needed

import pandas as pd

csv_file = ".csv"
csv_path = os.path.join(DATA_DIR, csv_file)

df = pd.read_csv(csv_path)

print("Validation dataset shape:", df.shape)
df.head()


# ==========================================================
# ðŸ”„ 3. Convert DataFrame to Earth Engine FeatureCollection
# ==========================================================
# Each row becomes an EE Feature with:
# - Point geometry
# - Reference attributes

def row_to_feature(row):
    geom = ee.Geometry.Point([row["lon"], row["lat"]])
    props = row.drop(["lon", "lat"]).to_dict()

    # Replace NaN values with None (EE-safe)
    for k, v in props.items():
        if pd.isna(v):
            props[k] = None

    return ee.Feature(geom, props)

features = df.apply(row_to_feature, axis=1).tolist()
fc = ee.FeatureCollection(features)

print("Validation points loaded:", fc.size().getInfo())


# ==========================================================
# ðŸ›° 4. Load Annual Mangrove Probability Assets
# ==========================================================
# Each asset contains a "classification" band (0â€“100)
# Converted to probability scale (0â€“1)

assetList = {
  2017: "image/2017",
  2018: "image/2018",
  2019: "image/2019",
  2020: "image/2020",
  2021: "image/2021",
  2022: "image/2022",
  2023: "image/2023",
  2024: "image/2024"
}

def load_prob(year):
    return (
        ee.Image(assetList[year])
        .select("classification")
        .divide(100)  # convert to 0â€“1 probability
        .rename(f"prob_{year}")
    )

years = list(range(2017, 2025))


# ==========================================================
# ðŸ“Œ 5. Sample Probability Values at Validation Points
# ==========================================================
# Stack all annual probability images into one multiband image
# Then sample once (efficient and correct approach)

prob_images = [load_prob(y) for y in years]
stacked = ee.Image.cat(prob_images)

fc_with_probs = stacked.sampleRegions(
    collection=fc,
    scale=10,
    geometries=True
)

print("Finished sampling probability values.")


# Convert EE FeatureCollection to Pandas DataFrame
props = [f["properties"] for f in fc_with_probs.getInfo()["features"]]
df_probs = pd.DataFrame(props)

print("Probability DataFrame shape:", df_probs.shape)
df_probs.head()


# ==========================================================
# ðŸ“ˆ 6. Compute ROC Curves (2017â€“2024)
# ==========================================================
# ROC evaluates classification performance across all thresholds
# AUC measures overall separability:
# - 0.5 = random
# - 0.7â€“0.8 = acceptable
# - 0.8â€“0.9 = strong
# - >0.9 = excellent

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
results = {}

for y in years:
    prob_col = f"prob_{y}"
    ref_col  = f"ref_{y}"

    if prob_col not in df_probs.columns:
        print(f"Missing {prob_col}")
        continue

    y_true  = df_probs[ref_col].astype(int)
    y_score = df_probs[prob_col].astype(float)

    fpr, tpr, _ = roc_curve(y_true, y_score)
    auc = roc_auc_score(y_true, y_score)
    results[y] = auc

    plt.plot(fpr, tpr, label=f"{y} (AUC={auc:.2f})")

# Random baseline
plt.plot([0,1], [0,1], 'k--')

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Mangrove Probability ROC Curves (2017â€“2024)")
plt.legend()
plt.grid(True)
plt.show()

print("AUC results per year:", results)
